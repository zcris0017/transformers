# transformers_introduction
This is a file that included comments to the code in a blog from Harvard NLP, The Annotated Transformer, which is included on (http://nlp.seas.harvard.edu/annotated-transformer/).
The original paper, Attention Is All You Need, is available on (https://arxiv.org/abs/1706.03762).

The comments could be stated in one line will be annoted with #, the comments using more than one line is annoted between \" or \""".

Please feel free to email me at zcr1281474170@163.com if there is anything wrong with the explanation to the codes.
